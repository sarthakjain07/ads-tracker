# ğŸ“º Video Advertisement Tracker (Golang + Kafka + PostgreSQL)

A scalable and resilient backend service to manage, track, and analyze video advertisement clicks in real time.

---

## ğŸš€ Features

- ğŸ” List video ads via REST API.
- ğŸ–± Track ad clicks asynchronously using Kafka.
- ğŸ“ˆ Real-time analytics (click counts, CTR).
- ğŸ§± PostgreSQL for persistent storage.
- ğŸ” Kafka-based decoupled architecture for resilience.
- ğŸ³ Fully containerized via Docker & Docker Compose.
- ğŸ“Š Prometheus-ready metrics endpoint (optional).

---

## ğŸ“¦ Tech Stack

- **Golang** â€” Core application logic
- **PostgreSQL** â€” Ad & Click data storage
- **Kafka** â€” Asynchronous event processing
- **Docker & Compose** â€” Development & deployment
- **Prometheus (optional)** â€” Monitoring & metrics

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/ads-tracker.git
cd ads-tracker

Build & Run (Dockerized)

docker-compose up -d --build

ğŸ“– API Documentation
ğŸ”¹ GET /ads

Fetches a list of available ads.
âœ… Response

[
  {
    "id": 1,
    "image_url": "https://example.com/image1.jpg",
    "target_url": "https://example.com"
  },
  ...
]

ğŸ”¹ POST /ads/click

Records a click event. Processes the request asynchronously using Kafka.
ğŸ“¤ Request

{
  "ad_id": 1,
  "timestamp": "2025-07-07T06:45:00Z",
  "ip": "192.168.1.1",
  "playback_time": 15
}

âœ… Response

{
  "message": "Click event received"
}

ğŸ”¹ GET /ads/analytics

Fetches real-time or near real-time ad performance metrics.
ğŸ”¸ Optional Query Params

    ?minutes=10 â†’ clicks in the last 10 minutes (default: all-time)

âœ… Response

[
  {
    "ad_id": 1,
    "clicks": 120,
    "ctr": 0.045
  },
  ...
]

ğŸ§  Concurrency & Processing Flow

The system uses Kafka for asynchronously processing click events.
ğŸ” Flow Summary

    API receives a click â†’ publishes to Kafka.

    Consumer service processes Kafka messages and inserts into DB.

    Analytics API queries aggregated data directly from DB.

This ensures:

    Low latency for users

    No data loss (even under DB or API failures)

    High scalability under spikes